# Yad-Tech: ASL-Translation-System
![383053835-a291aaf8-d2fe-454e-9f3e-b598a16eeb43](https://github.com/user-attachments/assets/adadda68-a74b-4456-87e5-5b5e11100f3f)
### Yad-Tech project Developed as part of the Samsung x Misk Innovation Campus program, Yad-Tech is designed to bridge the communication gap between the Deaf and hearing communities by instantly translating American Sign Language (ASL) gestures into text. It also serves as a valuable tool for those learning ASL. The project leverages Convolutional Neural Networks (CNNs) for gesture recognition, alongside a Random Forest model to fine-tune real-time predictions. By integrating Mediapipe for hand landmark detection and OpenCV for webcam functionality, Yad-Tech delivers a fast, accurate, and reliable experience for live applications.
